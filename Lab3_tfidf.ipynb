{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"======== 01-01\\nWritten by: Marta Kauffman & David Crane\\nMonica: There's nothing to tell! He's just some guy I work with!\\nJoey: C'mon, you're going out with the guy! There's gotta be something wrong wi\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = unicode(open('data/friends_transcripts.txt').read(), errors='ignore')\n",
    "contents[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First element of ``re.split`` is empty string, so skip it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "splitted = re.split('======== (\\d\\d)-(\\d\\d)\\n', contents)[1:]\n",
    "print(len(splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import izip\n",
    "\n",
    "def tripletswise(t):\n",
    "    it = iter(t)\n",
    "    return izip(it,it,it)\n",
    "\n",
    "def clean(txt):\n",
    "    for i in string.punctuation:\n",
    "        txt = txt.replace(i, '')\n",
    "    return txt\n",
    "\n",
    "matched_data = [(int(x), int(y), clean(z)) for x, y, z in tripletswise(splitted)]\n",
    "N = len(matched_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element is **season**,\n",
    "\n",
    "The second is **episode**,\n",
    "\n",
    "And the third â€“ actual **transcript**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def stem_data(data, use_stopwords=True):\n",
    "    def tokenize(doc):        \n",
    "        tokens = nltk.word_tokenize(doc.lower())\n",
    "        if use_stopwords:\n",
    "            return [t for t in tokens if not t in stopwords.words('english')]\n",
    "        else:\n",
    "            return tokens\n",
    "    \n",
    "    def stem(doc):\n",
    "        stemmer = PorterStemmer()\n",
    "        return [stemmer.stem(t) for t in tokenize(doc)]\n",
    "        \n",
    "    return [(seas, ep, stem(doc)) for seas, ep, doc in data]\n",
    "\n",
    "\n",
    "stemmed_data_w_stopwords = stem_data(matched_data, True)\n",
    "stemmed_data_wout_stopwords = stem_data(matched_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(stemmed_data_w_stopwords[0][2][:10])\n",
    "print(stemmed_data_wout_stopwords[0][2][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_doc_frequencies(data):\n",
    "    doc_frequencies = Counter()\n",
    "    for _, _, doc in data:\n",
    "        for w in set(doc):\n",
    "            doc_frequencies[w] += 1\n",
    "    \n",
    "    return doc_frequencies\n",
    "\n",
    "\n",
    "docfreq_w_stopwords = count_doc_frequencies(stemmed_data_w_stopwords)\n",
    "docfreq_wout_stopwords = count_doc_frequencies(stemmed_data_wout_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def sortdict(d):\n",
    "    return sorted(d.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "print(sortdict(docfreq_w_stopwords)[:10])\n",
    "print(sortdict(docfreq_wout_stopwords)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calc_tfidf(word, freq, doc_freq):\n",
    "    tf = freq\n",
    "    idf = math.log(N / (doc_freq[word] + 1))\n",
    "    return tf * idf\n",
    "\n",
    "def calculate_tfidf(data, document_frequencies, limit=5):\n",
    "    result = []\n",
    "    for seas, ep, script in data:\n",
    "        metricised = {}\n",
    "        for word, count in Counter(script).iteritems():\n",
    "            metric = calc_tfidf(word, count, document_frequencies)\n",
    "            metricised[word] = metric\n",
    "\n",
    "        tfidf_weighted = sortdict(metricised)\n",
    "    \n",
    "        result.append((seas, ep, tfidf_weighted[:limit]))\n",
    "        \n",
    "    return result\n",
    "        \n",
    "tfidf_w_stopwords = calculate_tfidf(stemmed_data_w_stopwords, docfreq_w_stopwords)\n",
    "tfidf_wout_stopwords = calculate_tfidf(stemmed_data_wout_stopwords, docfreq_wout_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_tfidf_data(tfidf_data):\n",
    "    for seas, ep, metrics in tfidf_data:\n",
    "        freq = \", \".join(\"{}: {:6.3f}\".format(x, y) for x, y in metrics)\n",
    "        print(\"Season {}, episode {}: {}\".format(seas, ep, freq))\n",
    "        print\n",
    "        \n",
    "print_tfidf_data(tfidf_w_stopwords[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipy_table import make_table\n",
    "\n",
    "make_table(tfidf_w_stopwords[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_tfidf_data(tfidf_wout_stopwords[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_table(tfidf_wout_stopwords[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x, y in zip(tfidf_w_stopwords, tfidf_wout_stopwords):\n",
    "    if x != y:\n",
    "        print(x)\n",
    "        print(y)\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Now just quickly do the same w/ stopwords for 2,3-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "bigrammed_data_w_stopwords = [(s, e, list(ngrams(d, 2))) for s, e, d in stemmed_data_w_stopwords]\n",
    "trigrammed_data_w_stopwords = [(s, e, list(ngrams(d, 3))) for s, e, d in stemmed_data_w_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_tfidf_data = calculate_tfidf(bigrammed_data_w_stopwords, count_doc_frequencies(bigrammed_data_w_stopwords))\n",
    "print_tfidf_data(bigram_tfidf_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_table(bigram_tfidf_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigram_tfidf_data = calculate_tfidf(trigrammed_data_w_stopwords, count_doc_frequencies(trigrammed_data_w_stopwords))\n",
    "print_tfidf_data(trigram_tfidf_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_table(trigram_tfidf_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
